<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Tensorflow.Keras</name>
    </assembly>
    <members>
        <member name="F:Tensorflow.Keras.Activations.Linear">
            <summary>
            Linear activation function (pass-through).
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.BackendImpl.PER_GRAPH_LAYER_NAME_UIDS">
            <summary>
            A global dictionary mapping graph objects to an index of counters used
            for various layer names in each graph.
            Allows to give unique autogenerated names to layers, in a graph-specific way.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.BackendImpl.spatial_2d_padding(Tensorflow.Tensor,NumSharp.NDArray,System.String)">
            <summary>
            Pads the 2nd and 3rd dimensions of a 4D tensor.
            </summary>
            <param name="x"></param>
            <param name="padding"></param>
            <param name="data_format"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.BackendImpl.eval_in_eager_or_function(Tensorflow.Tensor)">
            <summary>
            Method to evaluate a tensor in eager or in a tf.function.
            </summary>
            <param name="outputs"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Datasets.Mnist.load_data">
            <summary>
            Loads the [MNIST dataset](http://yann.lecun.com/exdb/mnist/).
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.DataHandler">
            <summary>
            Handles iterating over epoch-level `tf.data.Iterator` objects.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.IDataAdapter">
            <summary>
            In TF 2.0, tf.data is the preferred API for user to feed in data. In order
            to simplify the training code path, all the input data object will be
            converted to `tf.data.Dataset` if possible.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.DataAdapters.IDataAdapter.CanHandle(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Whether the current DataAdapter could handle the input x and y.
            </summary>
            <param name="x">input features</param>
            <param name="y">target labels</param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.DataAdapters.TensorLikeDataAdapter">
            <summary>
            Adapter that handles Tensor-like objects, e.g. EagerTensor and NumPy.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.DataAdapters.TensorLikeDataAdapter.slice_batch_indices(Tensorflow.Tensor)">
            <summary>
            Convert a Tensor of indices into a dataset of batched indices.
            </summary>
            <param name="tensor"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Functional">
            <summary>
            A `Functional` model is a `Model` defined as a directed graph of layers.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Functional._set_output_names">
            <summary>
            Assigns unique names to the Network's outputs.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Functional.MapGraphNetwork(Tensorflow.Tensors,Tensorflow.Tensors)">
            <summary>
            Validates a network's topology and gather its layers and nodes.
            </summary>
            <param name="inputs"></param>
            <param name="outputs"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Functional.BuildMap(Tensorflow.Tensors)">
            <summary>
            This method topologically sorts nodes in order from inputs to outputs.
            </summary>
            <param name="outputs"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Functional.get_network_config">
            <summary>
            Builds the config, which consists of the node graph and serialized layers.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Layer">
            <summary>
            Base layer class.
            A layer is a class implementing common neural networks operations, such
            as convolution, batch norm, etc. These operations require managing weights,
            losses, updates, and inter-layer connectivity.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer.Apply(Tensorflow.Tensors,Tensorflow.Tensor,System.Boolean)">
            <summary>
            Wraps `call`, applying pre- and post-processing steps.
            </summary>
            <param name="input"></param>
            <param name="state"></param>
            <param name="is_training"></param>
            <returns></returns>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.args">
            <summary>
            Arguments initialize layer.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.built">
            <summary>
            Indicates whether `build` needs to be called upon layer call, to create
            the layer's weights.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.stateful">
            <summary>
            A stateful layer is a layer whose updates are run during inference too,
            for instance stateful RNNs.
            </summary>
        </member>
        <member name="F:Tensorflow.Keras.Engine.Layer.inputSpec">
            <summary>
            Provides information about which inputs are compatible with the layer.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer.Call(Tensorflow.Tensors,Tensorflow.Tensor,System.Boolean)">
            <summary>
            Subclass has to override this method.
            </summary>
            <param name="inputs"></param>
            <param name="state"></param>
            <param name="is_training"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer._handle_weight_regularization(System.String,Tensorflow.IVariableV1,Tensorflow.Keras.IRegularizer)">
            <summary>
            Create lambdas which compute regularization losses.
            </summary>
            <param name="name"></param>
            <param name="variable"></param>
            <param name="regularizer"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer.load_weights(System.String)">
            <summary>
            Loads all layer weights, either from a TensorFlow or an HDF5 weight file.
            </summary>
            <param name="filepath"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Layer._get_trainable_state">
            <summary>
            Get the `trainable` state of each sublayer.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Engine.LossesContainer.Call(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Computes the overall loss.
            </summary>
            <param name="y_true"></param>
            <param name="y_pred"></param>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Model">
            <summary>
            `Model` groups layers into an object with training and inference features.
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Tensorflow.Keras.Engine.Model.evaluate(NumSharp.NDArray,NumSharp.NDArray,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean,System.Boolean)" -->
        <member name="M:Tensorflow.Keras.Engine.Model.fit(NumSharp.NDArray,NumSharp.NDArray,System.Int32,System.Int32,System.Int32,System.Single,System.Boolean,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Trains the model for a fixed number of epochs (iterations on a dataset).
            </summary>
            <param name="x"></param>
            <param name="y"></param>
            <param name="batch_size"></param>
            <param name="epochs"></param>
            <param name="verbose"></param>
            <param name="validation_split"></param>
            <param name="shuffle"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Model.predict(Tensorflow.Tensor,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Generates output predictions for the input samples.
            </summary>
            <param name="x">Input samples</param>
            <param name="batch_size">Number of samples per batch</param>
            <param name="verbose">Verbosity mode</param>
            <param name="steps">
            Total number of steps (batches of samples)
            before declaring the prediction round finished.
            </param>
            <param name="max_queue_size"></param>
            <param name="workers"></param>
            <param name="use_multiprocessing"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Model.save(System.String,System.Boolean,System.Boolean,System.String,Tensorflow.ModelSaving.SaveOptions)">
            <summary>
            Saves the model to Tensorflow SavedModel or a single HDF5 file.
            </summary>
            <param name="filepath"></param>
            <param name="overwrite"></param>
            <param name="include_optimizer"></param>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Model.summary(System.Int32,System.Single[])">
            <summary>
            Prints a string summary of the network.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Model.train_step(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            The logic for one training step.
            </summary>
            <param name="data"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Node">
            <summary>
            A `Node` describes the connectivity between two layers.
            
            Each time a layer is connected to some new input,
            a node is added to `layer._inbound_nodes`.
            Each time the output of a layer is used by another layer,
            a node is added to `layer._outbound_nodes`.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Node.MapArguments(System.Collections.Generic.Dictionary{System.Int32,System.Collections.Generic.Queue{Tensorflow.Tensor}})">
            <summary>
            Maps Keras Tensors to computed Tensors using `tensor_dict`.
            </summary>
            <param name="tensor_dict"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Node.serialize(System.Func{System.String,System.Int32,System.String},System.Collections.Generic.Dictionary{System.String,System.Int32})">
            <summary>
            Serializes `Node` for Functional API's `get_config`.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Engine.Sequential">
            <summary>
            `Sequential` groups a linear stack of layers into a `tf.keras.Model`.
            `Sequential` provides training and inference features on this model.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Engine.Sequential.add(Tensorflow.Keras.Engine.Layer)">
            <summary>
            Adds a layer instance on top of the layer stack.
            </summary>
            <param name="layer"></param>
        </member>
        <member name="M:Tensorflow.Keras.Initializers.he_normal(System.Nullable{System.Int32})">
            <summary>
            He normal initializer.
            </summary>
            <param name="seed"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.KerasInterface.Model(Tensorflow.Tensors,Tensorflow.Tensors,System.String)">
            <summary>
            `Model` groups layers into an object with training and inference features.
            </summary>
            <param name="input"></param>
            <param name="output"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.KerasInterface.Input(Tensorflow.TensorShape,System.Int32,Tensorflow.TF_DataType,System.String,System.Boolean,System.Boolean,Tensorflow.Tensor)">
            <summary>
            Instantiate a Keras tensor.
            </summary>
            <param name="shape"></param>
            <param name="batch_size"></param>
            <param name="dtype"></param>
            <param name="name"></param>
            <param name="sparse">
            A boolean specifying whether the placeholder to be created is sparse.
            </param>
            <param name="ragged">
            A boolean specifying whether the placeholder to be created is ragged.
            </param>
            <param name="tensor">
            Optional existing tensor to wrap into the `Input` layer.
            If set, the layer will not create a placeholder tensor.
            </param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Dense">
            <summary>
            Just your regular densely-connected NN layer.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Embedding">
            <summary>
            Turns positive integers (indexes) into dense vectors of fixed size.
            https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.InputLayer">
            <summary>
            Layer to be used as an entry point into a Network (a graph of layers).
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.batch_normalization(Tensorflow.Tensor,System.Int32,System.Single,System.Single,System.Boolean,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.Tensor,System.Boolean,System.String,System.Boolean,System.Single)">
            <summary>
            Functional interface for the batch normalization layer.
            http://arxiv.org/abs/1502.03167
            </summary>
            <param name="inputs"></param>
            <param name="axis"></param>
            <param name="momentum"></param>
            <param name="epsilon"></param>
            <param name="center"></param>
            <param name="scale"></param>
            <param name="beta_initializer"></param>
            <param name="gamma_initializer"></param>
            <param name="moving_mean_initializer"></param>
            <param name="moving_variance_initializer"></param>
            <param name="training"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="renorm"></param>
            <param name="renorm_momentum"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.Conv2D(System.Int32,Tensorflow.TensorShape,Tensorflow.TensorShape,System.String,System.String,Tensorflow.TensorShape,System.Int32,Tensorflow.Keras.Activation,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.Keras.IRegularizer,Tensorflow.Keras.IRegularizer,Tensorflow.Keras.IRegularizer)">
            <summary>
            
            </summary>
            <param name="filters"></param>
            <param name="kernel_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="data_format"></param>
            <param name="dilation_rate"></param>
            <param name="groups"></param>
            <param name="activation">tf.keras.activations</param>
            <param name="use_bias"></param>
            <param name="kernel_initializer"></param>
            <param name="bias_initializer"></param>
            <param name="kernel_regularizer"></param>
            <param name="bias_regularizer"></param>
            <param name="activity_regularizer"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.dense(Tensorflow.Tensor,System.Int32,Tensorflow.Keras.Activation,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,System.Boolean,System.String,System.Nullable{System.Boolean})">
            <summary>
                Densely-connected layer class. aka fully-connected<br></br>
                `outputs = activation(inputs * kernel + bias)`
            </summary>
            <param name="inputs"></param>
            <param name="units">Python integer, dimensionality of the output space.</param>
            <param name="activation"></param>
            <param name="use_bias">Boolean, whether the layer uses a bias.</param>
            <param name="kernel_initializer"></param>
            <param name="bias_initializer"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="reuse"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.Embedding(System.Int32,System.Int32,Tensorflow.IInitializer,System.Boolean,Tensorflow.TensorShape,System.Int32)">
            <summary>
            Turns positive integers (indexes) into dense vectors of fixed size.
            This layer can only be used as the first layer in a model.
            e.g. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]
            https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding
            </summary>
            <param name="input_dim">Size of the vocabulary, i.e. maximum integer index + 1.</param>
            <param name="output_dim">Dimension of the dense embedding.</param>
            <param name="embeddings_initializer">Initializer for the embeddings matrix (see keras.initializers).</param>
            <param name="mask_zero"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.Input(Tensorflow.TensorShape,System.String,System.Boolean,System.Boolean)">
            <summary>
            `Input()` is used to instantiate a Keras tensor.
            </summary>
            <param name="shape">A shape tuple not including the batch size.</param>
            <param name="name"></param>
            <param name="sparse"></param>
            <param name="ragged"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.max_pooling2d(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
            Max pooling layer for 2D inputs (e.g. images).
            </summary>
            <param name="inputs">The tensor over which to pool. Must have rank 4.</param>
            <param name="pool_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="data_format"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Layers.LayersApi.ZeroPadding2D(NumSharp.NDArray)">
            <summary>
            Zero-padding layer for 2D input (e.g. picture).
            </summary>
            <param name="padding"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Layers.LSTM">
            <summary>
            Long Short-Term Memory layer - Hochreiter 1997.
            
            See [the Keras RNN API guide](https://www.tensorflow.org/guide/keras/rnn)
            for details about the usage of RNN API.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.Rescaling">
            <summary>
            Multiply inputs by `scale` and adds `offset`.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Layers.ZeroPadding2D">
            <summary>
            Zero-padding layer for 2D input (e.g. picture).
            
            This layer can add rows and columns of zeros
            at the top, bottom, left and right side of an image tensor.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Losses.Loss">
            <summary>
            Loss base class.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Metrics.Mean">
            <summary>
            Computes the (weighted) mean of the given values.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Metrics.Metric">
            <summary>
            Encapsulates metric logic and state.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Metrics.MetricsApi.sparse_categorical_accuracy(Tensorflow.Tensor,Tensorflow.Tensor)">
            <summary>
            Calculates how often predictions matches integer labels.
            </summary>
            <param name="y_true">Integer ground truth values.</param>
            <param name="y_pred">The prediction values.</param>
            <returns>Sparse categorical accuracy values.</returns>
        </member>
        <member name="T:Tensorflow.Keras.Metrics.Reduce">
            <summary>
            Encapsulates metrics that perform a reduce operation on the values.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.Adam">
            <summary>
            Optimizer that implements the Adam algorithm.
            Adam optimization is a stochastic gradient descent method that is based on
            adaptive estimation of first-order and second-order moments.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Optimizers.OptimizerApi.Adam(System.Single,System.Single,System.Single,System.Single,System.Boolean,System.String)">
            <summary>
            Adam optimization is a stochastic gradient descent method that is based on
            adaptive estimation of first-order and second-order moments.
            </summary>
            <param name="learning_rate"></param>
            <param name="beta_1"></param>
            <param name="beta_2"></param>
            <param name="epsilon"></param>
            <param name="amsgrad"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Optimizers.OptimizerApi.RMSprop(System.Single,System.Single,System.Single,System.Single,System.Boolean,System.String)">
            <summary>
            Construct a new RMSprop optimizer.
            </summary>
            <param name="learning_rate"></param>
            <param name="rho"></param>
            <param name="momentum"></param>
            <param name="epsilon"></param>
            <param name="centered"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.OptimizerV2">
            <summary>
            Updated base class for optimizers.
            </summary>
        </member>
        <member name="M:Tensorflow.Keras.Optimizers.OptimizerV2.apply_gradients(System.Collections.Generic.IEnumerable{System.ValueTuple{Tensorflow.Tensor,Tensorflow.ResourceVariable}},System.String,System.Boolean)">
            <summary>
            Apply gradients to variables.
            </summary>
            <param name="grads_and_vars"></param>
            <param name="name"></param>
            <param name="experimental_aggregate_gradients"></param>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.PolynomialDecay">
            <summary>
            A LearningRateSchedule that uses a polynomial decay schedule.
            </summary>
        </member>
        <member name="T:Tensorflow.Keras.Optimizers.RMSprop">
            <summary>
            Optimizer that implements the RMSprop algorithm.
            </summary>
        </member>
        <!-- Badly formed XML comment ignored for member "M:Tensorflow.Keras.Preprocessings.DatasetUtils.get_training_or_validation_split``2(``0[],``1[],System.Single,System.String)" -->
        <member name="M:Tensorflow.Keras.Preprocessings.DatasetUtils.index_directory(System.String,System.String[],System.String[],System.Boolean,System.Nullable{System.Int32},System.Boolean)">
            <summary>
            Make list of all files in the subdirs of `directory`, with their labels.
            </summary>
            <param name="directory"></param>
            <param name="labels"></param>
            <param name="formats"></param>
            <param name="class_names"></param>
            <param name="shuffle"></param>
            <param name="seed"></param>
            <param name="follow_links"></param>
            <returns>
            file_paths, labels, class_names
            </returns>
        </member>
        <member name="M:Tensorflow.Keras.Preprocessing.image_dataset_from_directory(System.String,System.String,System.String,System.String[],System.String,System.Int32,Tensorflow.TensorShape,System.Boolean,System.Nullable{System.Int32},System.Single,System.String,System.String,System.Boolean)">
            <summary>
            Generates a `tf.data.Dataset` from image files in a directory.
            https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory
            </summary>
            <param name="directory">Directory where the data is located.</param>
            <param name="labels"></param>
            <param name="label_mode"></param>
            <param name="class_names"></param>
            <param name="color_mode"></param>
            <param name="batch_size"></param>
            <param name="image_size"></param>
            <param name="shuffle"></param>
            <param name="seed"></param>
            <param name="validation_split"></param>
            <param name="subset"></param>
            <param name="interpolation"></param>
            <param name="follow_links"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Sequence.pad_sequences(NumSharp.NDArray,System.Nullable{System.Int32},System.String,System.String,System.String,System.Object)">
            <summary>
            Pads sequences to the same length.
            https://keras.io/preprocessing/sequence/
            https://faroit.github.io/keras-docs/1.2.0/preprocessing/sequence/
            </summary>
            <param name="sequences">List of lists, where each element is a sequence.</param>
            <param name="maxlen">Int, maximum length of all sequences.</param>
            <param name="dtype">Type of the output sequences.</param>
            <param name="padding">String, 'pre' or 'post':</param>
            <param name="truncating">String, 'pre' or 'post'</param>
            <param name="value">Float or String, padding value.</param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.tensorflow_layers.layers_internal.batch_normalization(Tensorflow.Tensor,System.Int32,System.Single,System.Single,System.Boolean,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.IInitializer,Tensorflow.Tensor,System.Boolean,System.String,System.Boolean,System.Single)">
            <summary>
            Functional interface for the batch normalization layer.
            http://arxiv.org/abs/1502.03167
            </summary>
            <param name="inputs"></param>
            <param name="axis"></param>
            <param name="momentum"></param>
            <param name="epsilon"></param>
            <param name="center"></param>
            <param name="scale"></param>
            <param name="beta_initializer"></param>
            <param name="gamma_initializer"></param>
            <param name="moving_mean_initializer"></param>
            <param name="moving_variance_initializer"></param>
            <param name="training"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="renorm"></param>
            <param name="renorm_momentum"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.tensorflow_layers.layers_internal.max_pooling2d(Tensorflow.Tensor,System.Int32[],System.Int32[],System.String,System.String,System.String)">
            <summary>
            Max pooling layer for 2D inputs (e.g. images).
            </summary>
            <param name="inputs">The tensor over which to pool. Must have rank 4.</param>
            <param name="pool_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="data_format"></param>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.tensorflow_layers.layers_internal.dense(Tensorflow.Tensor,System.Int32,Tensorflow.Keras.Activation,System.Boolean,Tensorflow.IInitializer,Tensorflow.IInitializer,System.Boolean,System.String,System.Nullable{System.Boolean})">
            <summary>
                Densely-connected layer class. aka fully-connected<br></br>
                `outputs = activation(inputs * kernel + bias)`
            </summary>
            <param name="inputs"></param>
            <param name="units">Python integer, dimensionality of the output space.</param>
            <param name="activation"></param>
            <param name="use_bias">Boolean, whether the layer uses a bias.</param>
            <param name="kernel_initializer"></param>
            <param name="bias_initializer"></param>
            <param name="trainable"></param>
            <param name="name"></param>
            <param name="reuse"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.tensorflow_layers.layers_internal.flatten(Tensorflow.Tensor,System.String,System.String)">
            <summary>
                Flattens an input tensor while preserving the batch axis (axis 0).
            </summary>
            <param name="inputs">Tensor input.</param>
            <param name="name">The name of the layer.</param>
            <param name="data_format">
                A string, one of `channels_last` (default) or `channels_first`. <br></br>
                The ordering of the dimensions in the inputs. <br></br>
                `channels_last` corresponds to inputs with shape <br></br>
                `(batch, height, width, channels)` while `channels_first` corresponds to <br></br>
                inputs with shape `(batch, channels, height, width)`. 
            </param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Utils.base_layer_utils.make_variable(Tensorflow.VariableArgs)">
            <summary>
            Adds a new variable to the layer.
            </summary>
            <param name="args"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Utils.base_layer_utils.unique_layer_name(System.String,System.Collections.Generic.Dictionary{System.String,System.Int32},System.String[],System.Boolean)">
            <summary>
            Makes a layer name (or arbitrary string) unique within a TensorFlow graph.
            </summary>
            <param name="name"></param>
            <returns></returns>
        </member>
        <member name="M:Tensorflow.Keras.Utils.layer_utils.print_layer_summary(Tensorflow.Keras.ILayer,System.Int32[])">
            <summary>
            Prints a summary for a single layer.
            </summary>
            <param name="layer"></param>
        </member>
        <member name="T:System.Index">
            <summary>Represent a type can be used to index a collection either from the start or the end.</summary>
            <remarks>
            Index is used by the C# compiler to support the new index syntax
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 } ;
            int lastElement = someArray[^1]; // lastElement = 5
            </code>
            </remarks>
        </member>
        <member name="M:System.Index.#ctor(System.Int32,System.Boolean)">
            <summary>Construct an Index using a value and indicating if the index is from the start or from the end.</summary>
            <param name="value">The index value. it has to be zero or positive number.</param>
            <param name="fromEnd">Indicating if the index is from the start or from the end.</param>
            <remarks>
            If the Index constructed from the end, index value 1 means pointing at the last element and index value 0 means pointing at beyond last element.
            </remarks>
        </member>
        <member name="P:System.Index.Start">
            <summary>Create an Index pointing at first element.</summary>
        </member>
        <member name="P:System.Index.End">
            <summary>Create an Index pointing at beyond last element.</summary>
        </member>
        <member name="M:System.Index.FromStart(System.Int32)">
            <summary>Create an Index from the start at the position indicated by the value.</summary>
            <param name="value">The index value from the start.</param>
        </member>
        <member name="M:System.Index.FromEnd(System.Int32)">
            <summary>Create an Index from the end at the position indicated by the value.</summary>
            <param name="value">The index value from the end.</param>
        </member>
        <member name="P:System.Index.Value">
            <summary>Returns the index value.</summary>
        </member>
        <member name="P:System.Index.IsFromEnd">
            <summary>Indicates whether the index is from the start or the end.</summary>
        </member>
        <member name="M:System.Index.GetOffset(System.Int32)">
            <summary>Calculate the offset from the start using the giving collection length.</summary>
            <param name="length">The length of the collection that the Index will be used with. length has to be a positive value</param>
            <remarks>
            For performance reason, we don't validate the input length parameter and the returned offset value against negative values.
            we don't validate either the returned offset is greater than the input length.
            It is expected Index will be used with collections which always have non negative length/count. If the returned offset is negative and
            then used to index a collection will get out of range exception which will be same affect as the validation.
            </remarks>
        </member>
        <member name="M:System.Index.Equals(System.Object)">
            <summary>Indicates whether the current Index object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.Equals(System.Index)">
            <summary>Indicates whether the current Index object is equal to another Index object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Index.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Index.op_Implicit(System.Int32)~System.Index">
            <summary>Converts integer number to an Index.</summary>
        </member>
        <member name="M:System.Index.ToString">
            <summary>Converts the value of the current Index object to its equivalent string representation.</summary>
        </member>
        <member name="T:System.Range">
            <summary>Represent a range has start and end indexes.</summary>
            <remarks>
            Range is used by the C# compiler to support the range syntax.
            <code>
            int[] someArray = new int[5] { 1, 2, 3, 4, 5 };
            int[] subArray1 = someArray[0..2]; // { 1, 2 }
            int[] subArray2 = someArray[1..^0]; // { 2, 3, 4, 5 }
            </code>
            </remarks>
        </member>
        <member name="P:System.Range.Start">
            <summary>Represent the inclusive start index of the Range.</summary>
        </member>
        <member name="P:System.Range.End">
            <summary>Represent the exclusive end index of the Range.</summary>
        </member>
        <member name="M:System.Range.#ctor(System.Index,System.Index)">
            <summary>Construct a Range object using the start and end indexes.</summary>
            <param name="start">Represent the inclusive start index of the range.</param>
            <param name="end">Represent the exclusive end index of the range.</param>
        </member>
        <member name="M:System.Range.Equals(System.Object)">
            <summary>Indicates whether the current Range object is equal to another object of the same type.</summary>
            <param name="value">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.Equals(System.Range)">
            <summary>Indicates whether the current Range object is equal to another Range object.</summary>
            <param name="other">An object to compare with this object</param>
        </member>
        <member name="M:System.Range.GetHashCode">
            <summary>Returns the hash code for this instance.</summary>
        </member>
        <member name="M:System.Range.ToString">
            <summary>Converts the value of the current Range object to its equivalent string representation.</summary>
        </member>
        <member name="M:System.Range.StartAt(System.Index)">
            <summary>Create a Range object starting from start index to the end of the collection.</summary>
        </member>
        <member name="M:System.Range.EndAt(System.Index)">
            <summary>Create a Range object starting from first element in the collection to the end Index.</summary>
        </member>
        <member name="P:System.Range.All">
            <summary>Create a Range object starting from first element to the end.</summary>
        </member>
        <member name="M:System.Range.GetOffsetAndLength(System.Int32)">
            <summary>Calculate the start offset and length of range object using a collection length.</summary>
            <param name="length">The length of the collection that the range will be used with. length has to be a positive value.</param>
            <remarks>
            For performance reason, we don't validate the input length parameter against negative values.
            It is expected Range will be used with collections which always have non negative length/count.
            We validate the range is inside the length scope though.
            </remarks>
        </member>
        <member name="M:System.Runtime.CompilerServices.RuntimeHelpers.GetSubArray``1(``0[],System.Range)">
            <summary>
            Slices the specified array using the specified range.
            </summary>
        </member>
    </members>
</doc>

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "#Load Basic libraries\n",
    "import numpy as np\n",
    "\n",
    "#Data\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#Model\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import get_file\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "print(\"All libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función auxiliar que redimensiona un array dado\n",
    "def flatten(dimData, moves):\n",
    "    moves = np.array(moves)\n",
    "    moves = moves.reshape(len(moves), dimData)\n",
    "    moves = moves.astype('float32')\n",
    "    moves /= 255\n",
    "    return moves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga los datos\n",
    "os.chdir(\"D:/Documentos/UCM/TFG/Red Neuronal\")\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "moves, labels = [],[]\n",
    "dirMoves = [\"UP.csv\", \"DOWN.csv\", \"RIGHT.csv\", \"LEFT.csv\"]\n",
    "\n",
    "#Guarda todos los archivos de datos\n",
    "for dir in dirMoves:\n",
    "    #Este encoding es para que no genere caracteres extraños\n",
    "    file = open(dirMoves[dirMoves.index(dir)], encoding='utf-8-sig')\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    for row in reader:\n",
    "        #print(row)\n",
    "        moves.append(row)\n",
    "        labels.append(dirMoves.index(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de movimientos de entrenamiento:  481\n",
      "Numero de movimientos de prueba:  96\n"
     ]
    }
   ],
   "source": [
    "#Separa el conjunto de datos en datos de prueba y de entrenamiento\n",
    "#Se necesitaran mas de entrenamiento que de prueba\n",
    "segregation, index = 5,0\n",
    "train_moves, test_moves, train_labels, test_labels = [],[],[],[]\n",
    "\n",
    "for move, label in zip(moves, labels):\n",
    "    if index < segregation:\n",
    "        train_moves.append(move)\n",
    "        train_labels.append(label)\n",
    "        index += 1\n",
    "    else:\n",
    "        test_moves.append(move)\n",
    "        test_labels.append(label)\n",
    "        index = 0\n",
    "\n",
    "print('Numero de movimientos de entrenamiento: ', len(train_moves))\n",
    "print('Numero de movimientos de prueba: ', len(test_moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Aplana\" los datos con la funcion auxiliar\n",
    "dataDim = np.prod(len(moves[0]))\n",
    "train_data  = flatten(dataDim, train_moves)\n",
    "test_data = flatten(dataDim, test_moves)\n",
    "\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    "\n",
    "#Determina el número de clases que se van a utilizar \n",
    "classes = np.unique(train_labels)\n",
    "nClasses  = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 481 samples, validate on 96 samples\n",
      "Epoch 1/100\n",
      "481/481 [==============================] - 3s 5ms/step - loss: 1.3798 - accuracy: 0.3077 - val_loss: 1.3515 - val_accuracy: 0.4583\n",
      "Epoch 2/100\n",
      "481/481 [==============================] - 0s 52us/step - loss: 1.3453 - accuracy: 0.3992 - val_loss: 1.3070 - val_accuracy: 0.3958\n",
      "Epoch 3/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 1.2902 - accuracy: 0.4699 - val_loss: 1.2334 - val_accuracy: 0.5521\n",
      "Epoch 4/100\n",
      "481/481 [==============================] - 0s 35us/step - loss: 1.2216 - accuracy: 0.6029 - val_loss: 1.1593 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 1.1371 - accuracy: 0.6861 - val_loss: 1.0558 - val_accuracy: 0.7083\n",
      "Epoch 6/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 1.0616 - accuracy: 0.6736 - val_loss: 0.9833 - val_accuracy: 0.6979\n",
      "Epoch 7/100\n",
      "481/481 [==============================] - 0s 34us/step - loss: 0.9756 - accuracy: 0.7318 - val_loss: 0.8983 - val_accuracy: 0.7292\n",
      "Epoch 8/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.8751 - accuracy: 0.7588 - val_loss: 0.8145 - val_accuracy: 0.7708\n",
      "Epoch 9/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.8283 - accuracy: 0.7838 - val_loss: 0.8200 - val_accuracy: 0.6875\n",
      "Epoch 10/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.8232 - accuracy: 0.7526 - val_loss: 0.7201 - val_accuracy: 0.7917\n",
      "Epoch 11/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.7231 - accuracy: 0.8170 - val_loss: 0.6913 - val_accuracy: 0.8021\n",
      "Epoch 12/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.6982 - accuracy: 0.8046 - val_loss: 0.6678 - val_accuracy: 0.7812\n",
      "Epoch 13/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.6400 - accuracy: 0.8316 - val_loss: 0.6132 - val_accuracy: 0.8125\n",
      "Epoch 14/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.6165 - accuracy: 0.8316 - val_loss: 0.5809 - val_accuracy: 0.8438\n",
      "Epoch 15/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.5756 - accuracy: 0.8545 - val_loss: 0.5484 - val_accuracy: 0.8542\n",
      "Epoch 16/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.5716 - accuracy: 0.8378 - val_loss: 0.5999 - val_accuracy: 0.8438\n",
      "Epoch 17/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.5872 - accuracy: 0.8316 - val_loss: 0.5498 - val_accuracy: 0.8229\n",
      "Epoch 18/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.5366 - accuracy: 0.8628 - val_loss: 0.5371 - val_accuracy: 0.8229\n",
      "Epoch 19/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.5291 - accuracy: 0.8586 - val_loss: 0.5091 - val_accuracy: 0.8229\n",
      "Epoch 20/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.4859 - accuracy: 0.8732 - val_loss: 0.4776 - val_accuracy: 0.8646\n",
      "Epoch 21/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.4629 - accuracy: 0.8732 - val_loss: 0.4675 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.4524 - accuracy: 0.8857 - val_loss: 0.4687 - val_accuracy: 0.8646\n",
      "Epoch 23/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.4795 - accuracy: 0.8711 - val_loss: 0.4735 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.4570 - accuracy: 0.8732 - val_loss: 0.4360 - val_accuracy: 0.8646\n",
      "Epoch 25/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.4164 - accuracy: 0.8919 - val_loss: 0.4177 - val_accuracy: 0.8646\n",
      "Epoch 26/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.4026 - accuracy: 0.8940 - val_loss: 0.4110 - val_accuracy: 0.8646\n",
      "Epoch 27/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.3836 - accuracy: 0.9023 - val_loss: 0.4048 - val_accuracy: 0.8542\n",
      "Epoch 28/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.3846 - accuracy: 0.8940 - val_loss: 0.4680 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.4089 - accuracy: 0.8877 - val_loss: 0.4538 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.3702 - accuracy: 0.9002 - val_loss: 0.3899 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.3466 - accuracy: 0.9064 - val_loss: 0.3986 - val_accuracy: 0.8646\n",
      "Epoch 32/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.3525 - accuracy: 0.9085 - val_loss: 0.3965 - val_accuracy: 0.8542\n",
      "Epoch 33/100\n",
      "481/481 [==============================] - 0s 33us/step - loss: 0.3430 - accuracy: 0.9064 - val_loss: 0.3779 - val_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.3514 - accuracy: 0.8960 - val_loss: 0.3798 - val_accuracy: 0.8646\n",
      "Epoch 35/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.3285 - accuracy: 0.8898 - val_loss: 0.3532 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.3022 - accuracy: 0.9148 - val_loss: 0.3620 - val_accuracy: 0.8750\n",
      "Epoch 37/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.3000 - accuracy: 0.9168 - val_loss: 0.3614 - val_accuracy: 0.8958\n",
      "Epoch 38/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.3036 - accuracy: 0.9044 - val_loss: 0.3661 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2790 - accuracy: 0.9148 - val_loss: 0.3410 - val_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2709 - accuracy: 0.9168 - val_loss: 0.3768 - val_accuracy: 0.8646\n",
      "Epoch 41/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2924 - accuracy: 0.9085 - val_loss: 0.3829 - val_accuracy: 0.8750\n",
      "Epoch 42/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2780 - accuracy: 0.9064 - val_loss: 0.3354 - val_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.2543 - accuracy: 0.9231 - val_loss: 0.3423 - val_accuracy: 0.8854\n",
      "Epoch 44/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.2406 - accuracy: 0.9272 - val_loss: 0.3248 - val_accuracy: 0.9062\n",
      "Epoch 45/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2390 - accuracy: 0.9314 - val_loss: 0.3261 - val_accuracy: 0.9062\n",
      "Epoch 46/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.2408 - accuracy: 0.9293 - val_loss: 0.3285 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2317 - accuracy: 0.9272 - val_loss: 0.3372 - val_accuracy: 0.9062\n",
      "Epoch 48/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2449 - accuracy: 0.9231 - val_loss: 0.3725 - val_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2413 - accuracy: 0.9314 - val_loss: 0.3302 - val_accuracy: 0.9062\n",
      "Epoch 50/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2196 - accuracy: 0.9522 - val_loss: 0.3229 - val_accuracy: 0.9062\n",
      "Epoch 51/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2016 - accuracy: 0.9418 - val_loss: 0.3376 - val_accuracy: 0.9062\n",
      "Epoch 52/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2101 - accuracy: 0.9480 - val_loss: 0.3498 - val_accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2014 - accuracy: 0.9459 - val_loss: 0.3539 - val_accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2120 - accuracy: 0.9397 - val_loss: 0.3331 - val_accuracy: 0.9062\n",
      "Epoch 55/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.2026 - accuracy: 0.9543 - val_loss: 0.3281 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1988 - accuracy: 0.9501 - val_loss: 0.3741 - val_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.2151 - accuracy: 0.9418 - val_loss: 0.3230 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1715 - accuracy: 0.9543 - val_loss: 0.3300 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.1657 - accuracy: 0.9626 - val_loss: 0.3393 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1693 - accuracy: 0.9626 - val_loss: 0.3708 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1841 - accuracy: 0.9584 - val_loss: 0.3288 - val_accuracy: 0.9271\n",
      "Epoch 62/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1630 - accuracy: 0.9667 - val_loss: 0.3391 - val_accuracy: 0.9375\n",
      "Epoch 63/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1579 - accuracy: 0.9667 - val_loss: 0.3556 - val_accuracy: 0.9271\n",
      "Epoch 64/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1666 - accuracy: 0.9605 - val_loss: 0.3650 - val_accuracy: 0.9167\n",
      "Epoch 65/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1576 - accuracy: 0.9667 - val_loss: 0.3254 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1670 - accuracy: 0.9563 - val_loss: 0.3856 - val_accuracy: 0.9271\n",
      "Epoch 67/100\n",
      "481/481 [==============================] - 0s 28us/step - loss: 0.1823 - accuracy: 0.9459 - val_loss: 0.3152 - val_accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.1387 - accuracy: 0.9667 - val_loss: 0.3275 - val_accuracy: 0.9479\n",
      "Epoch 69/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1342 - accuracy: 0.9688 - val_loss: 0.3226 - val_accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1288 - accuracy: 0.9709 - val_loss: 0.3202 - val_accuracy: 0.9271\n",
      "Epoch 71/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.1407 - accuracy: 0.9647 - val_loss: 0.3735 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1383 - accuracy: 0.9647 - val_loss: 0.3675 - val_accuracy: 0.9271\n",
      "Epoch 73/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1242 - accuracy: 0.9709 - val_loss: 0.3492 - val_accuracy: 0.9271\n",
      "Epoch 74/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1328 - accuracy: 0.9647 - val_loss: 0.3594 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1270 - accuracy: 0.9688 - val_loss: 0.4006 - val_accuracy: 0.9271\n",
      "Epoch 76/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1362 - accuracy: 0.9647 - val_loss: 0.3390 - val_accuracy: 0.9271\n",
      "Epoch 77/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1209 - accuracy: 0.9709 - val_loss: 0.3271 - val_accuracy: 0.9375\n",
      "Epoch 78/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1184 - accuracy: 0.9688 - val_loss: 0.3729 - val_accuracy: 0.9271\n",
      "Epoch 79/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1199 - accuracy: 0.9751 - val_loss: 0.3860 - val_accuracy: 0.9271\n",
      "Epoch 80/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1464 - accuracy: 0.9501 - val_loss: 0.3775 - val_accuracy: 0.9271\n",
      "Epoch 81/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.3311 - val_accuracy: 0.9479\n",
      "Epoch 82/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1144 - accuracy: 0.9667 - val_loss: 0.3288 - val_accuracy: 0.9479\n",
      "Epoch 83/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1058 - accuracy: 0.9751 - val_loss: 0.3443 - val_accuracy: 0.9271\n",
      "Epoch 84/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1091 - accuracy: 0.9709 - val_loss: 0.3718 - val_accuracy: 0.9271\n",
      "Epoch 85/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.0988 - accuracy: 0.9751 - val_loss: 0.3522 - val_accuracy: 0.9375\n",
      "Epoch 86/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.0925 - accuracy: 0.9813 - val_loss: 0.3445 - val_accuracy: 0.9375\n",
      "Epoch 87/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1158 - accuracy: 0.9605 - val_loss: 0.3413 - val_accuracy: 0.9271\n",
      "Epoch 88/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.0999 - accuracy: 0.9751 - val_loss: 0.4255 - val_accuracy: 0.9375\n",
      "Epoch 89/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1325 - accuracy: 0.9563 - val_loss: 0.4623 - val_accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1109 - accuracy: 0.9688 - val_loss: 0.3626 - val_accuracy: 0.9479\n",
      "Epoch 91/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.0897 - accuracy: 0.9730 - val_loss: 0.3422 - val_accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.0910 - accuracy: 0.9771 - val_loss: 0.3695 - val_accuracy: 0.9271\n",
      "Epoch 93/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.0847 - accuracy: 0.9751 - val_loss: 0.3919 - val_accuracy: 0.9271\n",
      "Epoch 94/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.3571 - val_accuracy: 0.9375\n",
      "Epoch 95/100\n",
      "481/481 [==============================] - 0s 31us/step - loss: 0.0870 - accuracy: 0.9751 - val_loss: 0.3753 - val_accuracy: 0.9271\n",
      "Epoch 96/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.0829 - accuracy: 0.9813 - val_loss: 0.3511 - val_accuracy: 0.9375\n",
      "Epoch 97/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.0858 - accuracy: 0.9813 - val_loss: 0.4189 - val_accuracy: 0.9271\n",
      "Epoch 98/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.0916 - accuracy: 0.9751 - val_loss: 0.4554 - val_accuracy: 0.9375\n",
      "Epoch 99/100\n",
      "481/481 [==============================] - 0s 29us/step - loss: 0.1138 - accuracy: 0.9563 - val_loss: 0.4071 - val_accuracy: 0.9271\n",
      "Epoch 100/100\n",
      "481/481 [==============================] - 0s 27us/step - loss: 0.1003 - accuracy: 0.9667 - val_loss: 0.4178 - val_accuracy: 0.9271\n",
      "96/96 [==============================] - 0s 62us/step\n",
      "Resultado de la evaluación : Perdidas = 0.41781703382730484, Precisión = 0.9270833134651184\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               38656     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 171,268\n",
      "Trainable params: 171,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Para esta red neuronal se establecen tres capas, y 256 neuronas\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation = 'tanh', input_shape = (dataDim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "\n",
    "epochs = 100;\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size = 256, epochs=epochs, verbose=1,\n",
    "                    validation_data=(test_data, test_labels_one_hot))\n",
    "\n",
    "#test model\n",
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Resultado de la evaluación : Perdidas = {}, Precisión = {}\".format(test_loss, test_acc))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               38656     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 171,268\n",
      "Trainable params: 171,268\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Serializa el modelo para JSON\n",
    "model_json = model.to_json()\n",
    "model_path = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/model.json\"\n",
    "with open(model_path, \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "weights_path = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/model.h5\"\n",
    "#Serializa los pesos (weights) para HDF5\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "#Carga el json y crea el modelo\n",
    "json_file = open(model_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    " \n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "#Carga los pesos (weights) en el nuevo modelo\n",
    "loaded_model.load_weights(weights_path)\n",
    "\n",
    "#Test\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model expects input shape: ['N', 150]\n",
      "x shape: (481, 150)\n",
      "[7.5305969e-01 9.4845602e-03 2.3739211e-01 6.3674073e-05 9.9798536e-01\n",
      " 1.5387441e-04 9.4447525e-05 1.7663178e-03 9.9778819e-01 1.1104543e-03]\n"
     ]
    }
   ],
   "source": [
    "import keras2onnx as k2o\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# convert to onnx model\n",
    "onnx_model = k2o.convert_keras(model, model.name)\n",
    "\n",
    "#Save de onnx model\n",
    "temp_model_file = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/ONNX/model.onnx\"\n",
    "k2o.save_model(onnx_model, temp_model_file)\n",
    "\n",
    "try:\n",
    "    sess = onnxruntime.InferenceSession(temp_model_file)\n",
    "    ok = True    \n",
    "except (InvalidGraph, TypeError, RuntimeError) as e:\n",
    "    # Probably a mismatch between onnxruntime and onnx version.\n",
    "    print(e)\n",
    "    ok = False\n",
    "\n",
    "if ok:\n",
    "    print(\"The model expects input shape:\", sess.get_inputs()[0].shape)\n",
    "    print(\"x shape:\", train_data.shape)\n",
    "    \n",
    "\n",
    "    x = train_data if isinstance(train_data, list) else [train_data]\n",
    "        \n",
    "    feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])\n",
    "    pred_onnx = sess.run(None, feed)\n",
    "\n",
    "    prob = pred_onnx[0]\n",
    "    print(prob.ravel()[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

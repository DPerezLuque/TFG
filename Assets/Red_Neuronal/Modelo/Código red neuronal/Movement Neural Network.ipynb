{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "#Load Basic libraries\n",
    "import numpy as np\n",
    "\n",
    "#Data\n",
    "import os\n",
    "import csv\n",
    "\n",
    "#Model\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import get_file\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "print(\"All libraries loaded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función auxiliar que redimensiona un array dado\n",
    "def flatten(dimData, moves):\n",
    "    moves = np.array(moves)\n",
    "    moves = moves.reshape(len(moves), dimData)\n",
    "    moves = moves.astype('float32')\n",
    "    moves /= 255\n",
    "    return moves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga los datos\n",
    "os.chdir(\"D:/Documentos/UCM/TFG/Red Neuronal/Linear/Reposition\") #/Linear/Reposition #/Gyro #Gyro_Not\n",
    "os.getcwd()\n",
    "\n",
    "moves, labels = [],[]\n",
    "dirMoves = [\"UP.csv\", \"DOWN.csv\", \"LEFT.csv\", \"RIGHT.csv\", \"NONE.csv\"]\n",
    "\n",
    "#Guarda todos los archivos de datos\n",
    "for dir in dirMoves:\n",
    "    #Este encoding es para que no genere caracteres extraños\n",
    "    file = open(dirMoves[dirMoves.index(dir)], encoding='utf-8-sig')\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    for row in reader:\n",
    "        #print(row)\n",
    "        moves.append(row)\n",
    "        labels.append(dirMoves.index(dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de movimientos de entrenamiento:  744\n",
      "Numero de movimientos de prueba:  148\n"
     ]
    }
   ],
   "source": [
    "#Separa el conjunto de datos en datos de prueba y de entrenamiento\n",
    "#Se necesitaran mas de entrenamiento que de prueba\n",
    "segregation, index = 5,0\n",
    "train_moves, test_moves, train_labels, test_labels = [],[],[],[]\n",
    "\n",
    "for move, label in zip(moves, labels):\n",
    "    if index < segregation:\n",
    "        train_moves.append(move)\n",
    "        train_labels.append(label)\n",
    "        index += 1\n",
    "    else:\n",
    "        test_moves.append(move)\n",
    "        test_labels.append(label)\n",
    "        index = 0\n",
    "\n",
    "print('Numero de movimientos de entrenamiento: ', len(train_moves))\n",
    "print('Numero de movimientos de prueba: ', len(test_moves))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Aplana\" los datos con la funcion auxiliar\n",
    "dataDim = np.prod(len(moves[0]))\n",
    "train_data  = flatten(dataDim, train_moves)\n",
    "test_data = flatten(dataDim, test_moves)\n",
    "\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "test_labels = np.array(test_labels)\n",
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)\n",
    "\n",
    "#Determina el número de clases que se van a utilizar \n",
    "classes = np.unique(train_labels)\n",
    "nClasses  = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 744 samples, validate on 148 samples\n",
      "Epoch 1/100\n",
      "744/744 [==============================] - 0s 524us/step - loss: 1.5972 - accuracy: 0.2245 - val_loss: 1.5722 - val_accuracy: 0.2230\n",
      "Epoch 2/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 1.5676 - accuracy: 0.2366 - val_loss: 1.5551 - val_accuracy: 0.3311\n",
      "Epoch 3/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 1.4984 - accuracy: 0.4919 - val_loss: 1.5523 - val_accuracy: 0.2770\n",
      "Epoch 4/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 1.5061 - accuracy: 0.3737 - val_loss: 1.4560 - val_accuracy: 0.4459\n",
      "Epoch 5/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 1.3030 - accuracy: 0.6102 - val_loss: 1.8408 - val_accuracy: 0.2230\n",
      "Epoch 6/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 1.3960 - accuracy: 0.4409 - val_loss: 1.3487 - val_accuracy: 0.4257\n",
      "Epoch 7/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 1.1352 - accuracy: 0.5820 - val_loss: 1.3531 - val_accuracy: 0.4189\n",
      "Epoch 8/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 1.1727 - accuracy: 0.5121 - val_loss: 1.3292 - val_accuracy: 0.4459\n",
      "Epoch 9/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 1.0198 - accuracy: 0.6048 - val_loss: 1.2884 - val_accuracy: 0.4459\n",
      "Epoch 10/100\n",
      "744/744 [==============================] - 0s 42us/step - loss: 1.0782 - accuracy: 0.5699 - val_loss: 1.1919 - val_accuracy: 0.5203\n",
      "Epoch 11/100\n",
      "744/744 [==============================] - 0s 42us/step - loss: 1.0311 - accuracy: 0.6116 - val_loss: 1.3793 - val_accuracy: 0.3986\n",
      "Epoch 12/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.9397 - accuracy: 0.6210 - val_loss: 1.0939 - val_accuracy: 0.5473\n",
      "Epoch 13/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.7970 - accuracy: 0.6935 - val_loss: 1.0754 - val_accuracy: 0.5743\n",
      "Epoch 14/100\n",
      "744/744 [==============================] - 0s 42us/step - loss: 0.8831 - accuracy: 0.6707 - val_loss: 1.2728 - val_accuracy: 0.4797\n",
      "Epoch 15/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 1.0058 - accuracy: 0.5847 - val_loss: 1.0964 - val_accuracy: 0.5405\n",
      "Epoch 16/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.7680 - accuracy: 0.6949 - val_loss: 1.0539 - val_accuracy: 0.5473\n",
      "Epoch 17/100\n",
      "744/744 [==============================] - 0s 42us/step - loss: 0.7627 - accuracy: 0.6841 - val_loss: 1.1524 - val_accuracy: 0.5270\n",
      "Epoch 18/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.8765 - accuracy: 0.6250 - val_loss: 1.2504 - val_accuracy: 0.4932\n",
      "Epoch 19/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.8309 - accuracy: 0.6573 - val_loss: 1.0131 - val_accuracy: 0.5946\n",
      "Epoch 20/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.6856 - accuracy: 0.7487 - val_loss: 0.9803 - val_accuracy: 0.5608\n",
      "Epoch 21/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.7323 - accuracy: 0.6989 - val_loss: 1.0430 - val_accuracy: 0.5676\n",
      "Epoch 22/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.7247 - accuracy: 0.6976 - val_loss: 1.1849 - val_accuracy: 0.5068\n",
      "Epoch 23/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.7348 - accuracy: 0.7110 - val_loss: 1.0242 - val_accuracy: 0.6149\n",
      "Epoch 24/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.6665 - accuracy: 0.7849 - val_loss: 0.9542 - val_accuracy: 0.6622\n",
      "Epoch 25/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.7364 - accuracy: 0.7016 - val_loss: 1.1698 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.7887 - accuracy: 0.6586 - val_loss: 0.9070 - val_accuracy: 0.6689\n",
      "Epoch 27/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.5857 - accuracy: 0.8172 - val_loss: 0.8892 - val_accuracy: 0.6689\n",
      "Epoch 28/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.5744 - accuracy: 0.8185 - val_loss: 1.1010 - val_accuracy: 0.5608\n",
      "Epoch 29/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.9206 - accuracy: 0.6452 - val_loss: 1.0407 - val_accuracy: 0.5338\n",
      "Epoch 30/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.6306 - accuracy: 0.7755 - val_loss: 0.8520 - val_accuracy: 0.6622\n",
      "Epoch 31/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.5481 - accuracy: 0.8320 - val_loss: 0.8644 - val_accuracy: 0.6757\n",
      "Epoch 32/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.5404 - accuracy: 0.8212 - val_loss: 0.8598 - val_accuracy: 0.6824\n",
      "Epoch 33/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.5711 - accuracy: 0.7997 - val_loss: 1.0824 - val_accuracy: 0.5338\n",
      "Epoch 34/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.8060 - accuracy: 0.6452 - val_loss: 0.8567 - val_accuracy: 0.6689\n",
      "Epoch 35/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.5133 - accuracy: 0.8159 - val_loss: 0.8625 - val_accuracy: 0.6824\n",
      "Epoch 36/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.6019 - accuracy: 0.7917 - val_loss: 0.9010 - val_accuracy: 0.6892\n",
      "Epoch 37/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.5518 - accuracy: 0.8091 - val_loss: 0.8962 - val_accuracy: 0.6824\n",
      "Epoch 38/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.4938 - accuracy: 0.8226 - val_loss: 0.7852 - val_accuracy: 0.6959\n",
      "Epoch 39/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.5140 - accuracy: 0.8091 - val_loss: 0.9406 - val_accuracy: 0.6486\n",
      "Epoch 40/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.7515 - accuracy: 0.6935 - val_loss: 1.0033 - val_accuracy: 0.6486\n",
      "Epoch 41/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.5230 - accuracy: 0.8145 - val_loss: 0.7864 - val_accuracy: 0.6959\n",
      "Epoch 42/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4546 - accuracy: 0.8306 - val_loss: 0.8354 - val_accuracy: 0.6622\n",
      "Epoch 43/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.4436 - accuracy: 0.8293 - val_loss: 0.7848 - val_accuracy: 0.7027\n",
      "Epoch 44/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4891 - accuracy: 0.8199 - val_loss: 0.7685 - val_accuracy: 0.6892\n",
      "Epoch 45/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.4873 - accuracy: 0.8226 - val_loss: 1.2112 - val_accuracy: 0.4865\n",
      "Epoch 46/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.8083 - accuracy: 0.6788 - val_loss: 0.7640 - val_accuracy: 0.6757\n",
      "Epoch 47/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.4179 - accuracy: 0.8441 - val_loss: 0.7382 - val_accuracy: 0.7027\n",
      "Epoch 48/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4093 - accuracy: 0.8454 - val_loss: 0.7346 - val_accuracy: 0.7162\n",
      "Epoch 49/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.4294 - accuracy: 0.8414 - val_loss: 0.8722 - val_accuracy: 0.6757\n",
      "Epoch 50/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.4392 - accuracy: 0.8401 - val_loss: 0.8945 - val_accuracy: 0.6824\n",
      "Epoch 51/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.5371 - accuracy: 0.8038 - val_loss: 0.7470 - val_accuracy: 0.7230\n",
      "Epoch 52/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4191 - accuracy: 0.8414 - val_loss: 0.7351 - val_accuracy: 0.7432\n",
      "Epoch 53/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.4404 - accuracy: 0.8333 - val_loss: 0.8901 - val_accuracy: 0.6554\n",
      "Epoch 54/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4895 - accuracy: 0.7984 - val_loss: 0.7172 - val_accuracy: 0.7568\n",
      "Epoch 55/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3829 - accuracy: 0.8629 - val_loss: 0.7786 - val_accuracy: 0.7365\n",
      "Epoch 56/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.5896 - accuracy: 0.7702 - val_loss: 0.8699 - val_accuracy: 0.6892\n",
      "Epoch 57/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.3851 - accuracy: 0.8522 - val_loss: 0.6670 - val_accuracy: 0.7770\n",
      "Epoch 58/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3390 - accuracy: 0.8669 - val_loss: 0.6522 - val_accuracy: 0.7838\n",
      "Epoch 59/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.4125 - accuracy: 0.8441 - val_loss: 1.0035 - val_accuracy: 0.6622\n",
      "Epoch 60/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.6228 - accuracy: 0.7661 - val_loss: 0.7772 - val_accuracy: 0.7297\n",
      "Epoch 61/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.3621 - accuracy: 0.8629 - val_loss: 0.6539 - val_accuracy: 0.7905\n",
      "Epoch 62/100\n",
      "744/744 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.85 - 0s 38us/step - loss: 0.4214 - accuracy: 0.8347 - val_loss: 0.6901 - val_accuracy: 0.7500\n",
      "Epoch 63/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3567 - accuracy: 0.8710 - val_loss: 0.6481 - val_accuracy: 0.7635\n",
      "Epoch 64/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.3458 - accuracy: 0.8656 - val_loss: 0.6904 - val_accuracy: 0.7365\n",
      "Epoch 65/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3347 - accuracy: 0.8790 - val_loss: 0.7276 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4800 - accuracy: 0.8065 - val_loss: 0.9674 - val_accuracy: 0.6216\n",
      "Epoch 67/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.5121 - accuracy: 0.8132 - val_loss: 0.7254 - val_accuracy: 0.7162\n",
      "Epoch 68/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3042 - accuracy: 0.8763 - val_loss: 0.6083 - val_accuracy: 0.8108\n",
      "Epoch 69/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.2864 - accuracy: 0.8898 - val_loss: 0.6168 - val_accuracy: 0.7973\n",
      "Epoch 70/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.2912 - accuracy: 0.8992 - val_loss: 0.9694 - val_accuracy: 0.6757\n",
      "Epoch 71/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.4684 - accuracy: 0.8293 - val_loss: 0.7424 - val_accuracy: 0.7500\n",
      "Epoch 72/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.3726 - accuracy: 0.8548 - val_loss: 0.5722 - val_accuracy: 0.8176\n",
      "Epoch 73/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.2815 - accuracy: 0.8871 - val_loss: 0.6524 - val_accuracy: 0.7703\n",
      "Epoch 74/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.3530 - accuracy: 0.8508 - val_loss: 0.6655 - val_accuracy: 0.7838\n",
      "Epoch 75/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.3741 - accuracy: 0.8575 - val_loss: 0.6058 - val_accuracy: 0.8108\n",
      "Epoch 76/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.3106 - accuracy: 0.8804 - val_loss: 0.6954 - val_accuracy: 0.7500\n",
      "Epoch 77/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3235 - accuracy: 0.8710 - val_loss: 0.5758 - val_accuracy: 0.8108\n",
      "Epoch 78/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3327 - accuracy: 0.8723 - val_loss: 0.7308 - val_accuracy: 0.7365\n",
      "Epoch 79/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.3121 - accuracy: 0.8871 - val_loss: 0.5345 - val_accuracy: 0.8446\n",
      "Epoch 80/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3425 - accuracy: 0.8602 - val_loss: 0.7926 - val_accuracy: 0.7432\n",
      "Epoch 81/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3698 - accuracy: 0.8589 - val_loss: 0.6516 - val_accuracy: 0.7973\n",
      "Epoch 82/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3328 - accuracy: 0.8669 - val_loss: 0.5128 - val_accuracy: 0.8446\n",
      "Epoch 83/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.2447 - accuracy: 0.9113 - val_loss: 0.5194 - val_accuracy: 0.8378\n",
      "Epoch 84/100\n",
      "744/744 [==============================] - ETA: 0s - loss: 0.1868 - accuracy: 0.92 - 0s 40us/step - loss: 0.2203 - accuracy: 0.9288 - val_loss: 0.7266 - val_accuracy: 0.7568\n",
      "Epoch 85/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3877 - accuracy: 0.8481 - val_loss: 0.6166 - val_accuracy: 0.7973\n",
      "Epoch 86/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.2734 - accuracy: 0.8925 - val_loss: 0.5338 - val_accuracy: 0.8176\n",
      "Epoch 87/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.2196 - accuracy: 0.9153 - val_loss: 0.5446 - val_accuracy: 0.8243\n",
      "Epoch 88/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.3446 - accuracy: 0.8790 - val_loss: 0.9005 - val_accuracy: 0.6892\n",
      "Epoch 89/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.4753 - accuracy: 0.8159 - val_loss: 0.4691 - val_accuracy: 0.8514\n",
      "Epoch 90/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.2235 - accuracy: 0.9194 - val_loss: 0.5075 - val_accuracy: 0.8311\n",
      "Epoch 91/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.2077 - accuracy: 0.9234 - val_loss: 0.4873 - val_accuracy: 0.8716\n",
      "Epoch 92/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.2140 - accuracy: 0.9207 - val_loss: 0.6168 - val_accuracy: 0.7905\n",
      "Epoch 93/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.2040 - accuracy: 0.9261 - val_loss: 0.5286 - val_accuracy: 0.8378\n",
      "Epoch 94/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.1913 - accuracy: 0.9328 - val_loss: 0.5422 - val_accuracy: 0.8176\n",
      "Epoch 95/100\n",
      "744/744 [==============================] - 0s 38us/step - loss: 0.2182 - accuracy: 0.9140 - val_loss: 0.8059 - val_accuracy: 0.7365\n",
      "Epoch 96/100\n",
      "744/744 [==============================] - 0s 40us/step - loss: 0.7363 - accuracy: 0.7366 - val_loss: 0.5095 - val_accuracy: 0.8514\n",
      "Epoch 97/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.2366 - accuracy: 0.9073 - val_loss: 0.4550 - val_accuracy: 0.8649\n",
      "Epoch 98/100\n",
      "744/744 [==============================] - 0s 39us/step - loss: 0.1826 - accuracy: 0.9395 - val_loss: 0.4570 - val_accuracy: 0.8784\n",
      "Epoch 99/100\n",
      "744/744 [==============================] - 0s 37us/step - loss: 0.1776 - accuracy: 0.9395 - val_loss: 0.4901 - val_accuracy: 0.8649\n",
      "Epoch 100/100\n",
      "744/744 [==============================] - 0s 36us/step - loss: 0.1957 - accuracy: 0.9301 - val_loss: 0.4754 - val_accuracy: 0.8581\n",
      "148/148 [==============================] - 0s 94us/step\n",
      "Resultado de la evaluación : Perdidas = 0.4753970713228793, Precisión = 0.8581081032752991\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 625)               94375     \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 5)                 3130      \n",
      "=================================================================\n",
      "Total params: 880,005\n",
      "Trainable params: 880,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Para esta red neuronal se establecen tres capas, y 256 neuronas\n",
    "model = Sequential()\n",
    "model.add(Dense(625, activation = 'tanh', input_shape = (dataDim,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(625, activation='tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(625, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nClasses, activation='softmax'))\n",
    "\n",
    "\n",
    "epochs = 100;\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_data, train_labels_one_hot, batch_size = 256, epochs=epochs, verbose=1,\n",
    "                    validation_data=(test_data, test_labels_one_hot))\n",
    "\n",
    "#test model\n",
    "[test_loss, test_acc] = model.evaluate(test_data, test_labels_one_hot)\n",
    "print(\"Resultado de la evaluación : Perdidas = {}, Precisión = {}\".format(test_loss, test_acc))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 625)               94375     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 3130      \n",
      "=================================================================\n",
      "Total params: 880,005\n",
      "Trainable params: 880,005\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Serializa el modelo para JSON\n",
    "model_json = model.to_json()\n",
    "model_path = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/model.json\"\n",
    "with open(model_path, \"w\") as json_file:\n",
    "  json_file.write(model_json)\n",
    "\n",
    "weights_path = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/model.h5\"\n",
    "#Serializa los pesos (weights) para HDF5\n",
    "model.save_weights(weights_path)\n",
    "\n",
    "#Carga el json y crea el modelo\n",
    "json_file = open(model_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    " \n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "#Carga los pesos (weights) en el nuevo modelo\n",
    "loaded_model.load_weights(weights_path)\n",
    "\n",
    "#Test\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The ONNX operator number change on the optimization: 19 -> 12\n",
      "The maximum opset needed by this model is only 9.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model expects input shape: ['N', 150]\n",
      "x shape: (744, 150)\n",
      "[1.0000000e+00 4.5264237e-25 2.8429751e-08 1.2731288e-12 4.1358800e-16\n",
      " 9.9398369e-01 1.7454290e-06 1.4372577e-03 2.5759778e-06 4.5747906e-03]\n"
     ]
    }
   ],
   "source": [
    "import keras2onnx as k2o\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "# convert to onnx model\n",
    "onnx_model = k2o.convert_keras(model, model.name)\n",
    "\n",
    "#Save de onnx model\n",
    "temp_model_file = \"D:/Documentos/UCM/TFG/Red Neuronal/Modelo/ONNX/model.onnx\"\n",
    "k2o.save_model(onnx_model, temp_model_file)\n",
    "\n",
    "try:\n",
    "    sess = onnxruntime.InferenceSession(temp_model_file)\n",
    "    ok = True    \n",
    "except (InvalidGraph, TypeError, RuntimeError) as e:\n",
    "    # Probably a mismatch between onnxruntime and onnx version.\n",
    "    print(e)\n",
    "    ok = False\n",
    "\n",
    "if ok:\n",
    "    print(\"The model expects input shape:\", sess.get_inputs()[0].shape)\n",
    "    print(\"x shape:\", train_data.shape)\n",
    "    \n",
    "\n",
    "    x = train_data if isinstance(train_data, list) else [train_data]\n",
    "        \n",
    "    feed = dict([(input.name, x[n]) for n, input in enumerate(sess.get_inputs())])\n",
    "    pred_onnx = sess.run(None, feed)\n",
    "\n",
    "    prob = pred_onnx[0]\n",
    "    print(prob.ravel()[:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
